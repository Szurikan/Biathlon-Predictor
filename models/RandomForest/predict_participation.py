import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import os
import joblib
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score

def predict_participation(data_path, target_column, output_dir="data/"):
    df = pd.read_csv(data_path)

    # IÅ¡renkame varÅ¾ybÅ³ stulpelius, pradedanÄius su data (YYYY-MM-DD)
    competition_columns = [col for col in df.columns if col.startswith("202")]
    
    if target_column not in df.columns:
        raise ValueError(f"Nurodytas stulpelis '{target_column}' nerastas faile.")

    # Surikiuojame stulpelius chronologiÅ¡kai
    competition_columns_sorted = sorted(
        competition_columns, 
        key=lambda x: datetime.strptime(x.split(" ")[0], "%Y-%m-%d")
    )
    
    # Tikslo stulpelio indeksas sÄ…raÅ¡e
    target_index = competition_columns_sorted.index(target_column)
    
    # Tik ankstesniÅ³ varÅ¾ybÅ³ stulpeliai
    past_columns = competition_columns_sorted[:target_index]
    
    # Saugiklis: tikriname, ar tikslo stulpelis tikrai nepatenka Ä¯ poÅ¾ymius
    assert target_column not in past_columns, "Klaida: tikslo stulpelis pateko Ä¯ poÅ¾ymius!"
    
    # Statiniai poÅ¾ymiai (visi ne datos stulpeliai, iÅ¡skyrus ID ir vardÄ…)
    static_features = [col for col in df.columns if not col.startswith("202") and col not in ["IBUId", "FullName"]]

    # Atrenkame tik eilutes su Å¾inomais tikslo duomenimis
    df_model = df.dropna(subset=[target_column])
    
    # PoÅ¾ymiai ir tikslas
    X = df_model[static_features + past_columns]
    y = df_model[target_column].astype(int)
    
    # Dar vienas saugiklis: tikslo stulpelis neturi bÅ«ti tarp poÅ¾ymiÅ³
    assert target_column not in X.columns, "Klaida: tikslo stulpelis yra tarp poÅ¾ymiÅ³!"

    # DuomenÅ³ padalijimas mokymuisi ir testavimui
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # # Modelio kÅ«rimas ir mokymas
    # model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
    # model.fit(X_train, y_train)

    # Nustatome F1-score kaip optimizavimo kriterijÅ³
    f1 = make_scorer(f1_score, average='macro')

    # Tinklo paieÅ¡ka (GridSearch)
    param_grid = {
        'n_estimators': list(range(5, 305, 5))
    }

    grid_search = GridSearchCV(
        RandomForestClassifier(class_weight='balanced', random_state=42),
        param_grid=param_grid,
        scoring=f1,
        cv=5,  # 5-kartinÄ— kirtinÄ— validacija
        n_jobs=-1,
        verbose=1
    )

    print("\nğŸ” Vykdoma GridSearchCV optimizacija...")
    grid_search.fit(X_train, y_train)

    # Geriausias modelis
    model = grid_search.best_estimator_
    print(f"\nâœ… Geriausias modelis: n_estimators={grid_search.best_params_['n_estimators']} su F1-score={grid_search.best_score_:.4f}")


    # Sukuriame DataFrame su poÅ¾ymiÅ³ svarbomis
    importances = model.feature_importances_
    feature_names = X.columns
    feature_importance = pd.DataFrame({
        "Feature": feature_names,
        "Importance": importances
    }).sort_values(by="Importance", ascending=False)

    # Pasirenkame 10 svarbiausiÅ³
    top_features = feature_importance.head(10)

    # PieÅ¡iame stulpelinÄ™ diagramÄ…
    plt.figure(figsize=(10, 6))
    plt.barh(top_features["Feature"], top_features["Importance"], align="center")
    plt.gca().invert_yaxis()  # Svarbiausi virÅ¡uje
    plt.xlabel("Svarba (feature importance)")
    plt.title("10 svarbiausiÅ³ poÅ¾ymiÅ³ pagal Ä¯takÄ… prognozei")
    plt.tight_layout()
    plt.show()

    # BraiÅ¾ome visÅ³ bandymÅ³ rezultatus
    results = pd.DataFrame(grid_search.cv_results_)

    plt.figure(figsize=(10, 6))
    plt.plot(results['param_n_estimators'], results['mean_test_score'], marker='o')
    plt.xlabel("n_estimators")
    plt.ylabel("Vidutinis F1-score (5-fold CV)")
    plt.title("F1-score priklausomybÄ— nuo n_estimators")
    plt.grid(True)
    plt.tight_layout()
    plt.show()


    # Modelio iÅ¡saugojimas (su poÅ¾ymiÅ³ sÄ…raÅ¡u)
    os.makedirs(output_dir, exist_ok=True)
    model_path = os.path.join(output_dir, f"model_{target_column.replace(' ', '_').replace('(', '').replace(')', '')}.pkl")
    # IÅ¡saugome modelÄ¯ kartu su poÅ¾ymiÅ³ sÄ…raÅ¡u
    joblib.dump((model, list(X.columns)), model_path)
    print(f"Modelis iÅ¡saugotas: {model_path}")

    # Modelio Ä¯vertinimas
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, output_dict=False)
    print(f"\nModelio rezultatai prognozuojant '{target_column}':\n")
    print(report)

    # PrognozÄ— visoms sportininkÄ—ms
    df_all = df.copy()
    df_all_features = df_all[static_features + past_columns].copy()
    df_all_features = df_all_features.fillna(0)
    
    # Dar vienas saugiklis prieÅ¡ prognozavimÄ…
    assert target_column not in df_all_features.columns, "Klaida: tikslo stulpelis yra prognozavimo poÅ¾ymiuose!"
    
    df_all["PredictedParticipation"] = model.predict(df_all_features)

    # IÅ¡saugoti prognoziÅ³ failÄ…
    output_csv = os.path.join(output_dir, f"predictions_{target_column.replace(' ', '_').replace('(', '').replace(')', '')}.csv")
    df_all[["FullName", "PredictedParticipation"]].to_csv(output_csv, index=False)
    print(f"\nPrognoziÅ³ failas sukurtas: {output_csv}")

    # Parodyti sportininkes, kurioms prognozuojamas dalyvavimas
    predicted_names = df_all[df_all["PredictedParticipation"] == 1]["FullName"]
    print("\nVISOS sportininkÄ—s, kurioms prognozuojamas DALYVAVIMAS Å¡iame etape:")
    for name in predicted_names:
        print("-", name)

if __name__ == "__main__":
    predict_participation(
        data_path="data/female_athletes_binary_competitions.csv",
        target_column="2025-02-16 07 (10  Pursuit Competition) W"
    )