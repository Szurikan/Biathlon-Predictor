import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score
import os
import joblib
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

def predict_participation(data_path, target_column, output_dir="data/"):
    df = pd.read_csv(data_path)

    competition_columns = [col for col in df.columns if col.startswith("202")]
    competition_columns_sorted = sorted(
        competition_columns, 
        key=lambda x: datetime.strptime(x.split(" ")[0], "%Y-%m-%d")
    )

    static_features = [col for col in df.columns if not col.startswith("202") and col not in ["IBUId", "FullName"]]

    train_end_date = "2024-12-22"
    val_end_date = "2025-01-25"

    train_columns = [col for col in competition_columns_sorted 
                     if datetime.strptime(col.split(" ")[0], "%Y-%m-%d") <= datetime.strptime(train_end_date, "%Y-%m-%d")]
    val_columns = [col for col in competition_columns_sorted 
                   if datetime.strptime(train_end_date, "%Y-%m-%d") < datetime.strptime(col.split(" ")[0], "%Y-%m-%d") <= datetime.strptime(val_end_date, "%Y-%m-%d")]
    test_columns = [col for col in competition_columns_sorted 
                    if datetime.strptime(col.split(" ")[0], "%Y-%m-%d") > datetime.strptime(val_end_date, "%Y-%m-%d")]

    print(f"Treniravimo etap≈≥: {len(train_columns)}")
    print(f"Validacijos etap≈≥: {len(val_columns)}")
    print(f"Testavimo etap≈≥: {len(test_columns)}")

    X_train = df[static_features + train_columns]
    y_train = df[val_columns[0]].fillna(0).astype(float)

    param_grid = {'n_estimators': list(range(50, 251, 50))}

    print("\nüîç Vykdoma GridSearchCV optimizacija...")
    grid_search = GridSearchCV(
        RandomForestRegressor(random_state=42),
        param_grid=param_grid,
        scoring="neg_mean_squared_error",
        cv=3,
        n_jobs=-1,
        verbose=1
    )
    grid_search.fit(X_train, y_train)
    model = grid_search.best_estimator_

    print(f"\n‚úÖ Geriausias modelis: n_estimators={grid_search.best_params_['n_estimators']} su MSE={-grid_search.best_score_:.4f}")

    # Validacijos rezultatai
    print("\nüìä Validacijos rezultatai:")
    val_accuracy = []
    val_precision = []
    val_recall = []
    val_f1 = []

    for val_target in val_columns[1:]:
        y_val = df[val_target].fillna(0).astype(float)
        y_val_binary = y_val.astype(int)  # Konvertuojame ƒØ dvejetainƒØ formatƒÖ statistikos skaiƒçiavimui
        
        raw_preds = model.predict(X_train)
        val_pred = adjust_predictions_by_format(raw_preds, val_target)
        
        # Skaiƒçiuojame statistikas
        accuracy = accuracy_score(y_val_binary, val_pred)
        precision = precision_score(y_val_binary, val_pred, zero_division=0)
        recall = recall_score(y_val_binary, val_pred, zero_division=0)
        f1 = f1_score(y_val_binary, val_pred, zero_division=0)
        
        val_accuracy.append(accuracy)
        val_precision.append(precision)
        val_recall.append(recall)
        val_f1.append(f1)
        
        # Statistik≈≥ lentelƒó
        print(f"\nEtapas {val_target}:")
        print(f"Vidutinƒó prognozƒó: {np.mean(raw_preds):.4f}, Pasirinktos sportininkƒós: {sum(val_pred)}")
        print("\nStatistikos:")
        print(f"{'':12} precision    recall  f1-score   support")
        print(f"{'0':12} {precision_score(y_val_binary, val_pred, pos_label=0, zero_division=0):.2f}      {recall_score(y_val_binary, val_pred, pos_label=0, zero_division=0):.2f}     {f1_score(y_val_binary, val_pred, pos_label=0, zero_division=0):.2f}       {sum(y_val_binary == 0)}")
        print(f"{'1':12} {precision:.2f}      {recall:.2f}     {f1:.2f}       {sum(y_val_binary == 1)}")
        print(f"\naccuracy{'':<7} {'':<5} {'':<5} {accuracy:.2f}       {len(y_val_binary)}")
        print(f"macro avg{'':<4} {np.mean([precision_score(y_val_binary, val_pred, pos_label=0, zero_division=0), precision]):.2f}      {np.mean([recall_score(y_val_binary, val_pred, pos_label=0, zero_division=0), recall]):.2f}     {np.mean([f1_score(y_val_binary, val_pred, pos_label=0, zero_division=0), f1]):.2f}       {len(y_val_binary)}")
        print(f"weighted avg{''} {precision_score(y_val_binary, val_pred, average='weighted', zero_division=0):.2f}      {recall_score(y_val_binary, val_pred, average='weighted', zero_division=0):.2f}     {f1_score(y_val_binary, val_pred, average='weighted', zero_division=0):.2f}       {len(y_val_binary)}")
        
        # Sujaukimo matrica
        cm = confusion_matrix(y_val_binary, val_pred)
        print("\nSujaukimo matrica:")
        print(f"TN: {cm[0,0]}, FP: {cm[0,1]}")
        print(f"FN: {cm[1,0]}, TP: {cm[1,1]}")

    # Rengiame galutinƒØ modelƒØ
    X_final = df[static_features + train_columns + val_columns]
    y_final = df[test_columns[0]].fillna(0).astype(float)

    final_model = RandomForestRegressor(
        n_estimators=grid_search.best_params_['n_estimators'],
        random_state=42
    )

    print("\nüîÑ Treninguojamas galutinis modelis su visais ≈æinomais duomenimis...")
    final_model.fit(X_final, y_final)

    # Testavimo rezultatai
    print("\nüìã Testavimo rezultatai:")
    test_accuracy = []
    test_precision = []
    test_recall = []
    test_f1 = []
    test_etapai = []

    for test_target in test_columns[1:]:
        y_test = df[test_target].fillna(0).astype(float)
        y_test_binary = y_test.astype(int)
        
        raw_preds = final_model.predict(X_final)
        test_pred = adjust_predictions_by_format(raw_preds, test_target)
        
        # Skaiƒçiuojame statistikas
        accuracy = accuracy_score(y_test_binary, test_pred)
        precision = precision_score(y_test_binary, test_pred, zero_division=0)
        recall = recall_score(y_test_binary, test_pred, zero_division=0)
        f1 = f1_score(y_test_binary, test_pred, zero_division=0)
        
        test_accuracy.append(accuracy)
        test_precision.append(precision)
        test_recall.append(recall)
        test_f1.append(f1)
        test_etapai.append(datetime.strptime(test_target.split(" ")[0], "%Y-%m-%d"))
        
        # Statistik≈≥ lentelƒó
        print(f"\nEtapas {test_target}:")
        print(f"Vidutinƒó prognozƒó: {np.mean(raw_preds):.4f}, Pasirinktos sportininkƒós: {sum(test_pred)}")
        print("\nStatistikos:")
        print(f"{'':12} precision    recall  f1-score   support")
        print(f"{'0':12} {precision_score(y_test_binary, test_pred, pos_label=0, zero_division=0):.2f}      {recall_score(y_test_binary, test_pred, pos_label=0, zero_division=0):.2f}     {f1_score(y_test_binary, test_pred, pos_label=0, zero_division=0):.2f}       {sum(y_test_binary == 0)}")
        print(f"{'1':12} {precision:.2f}      {recall:.2f}     {f1:.2f}       {sum(y_test_binary == 1)}")
        print(f"\naccuracy{'':<7} {'':<5} {'':<5} {accuracy:.2f}       {len(y_test_binary)}")
        print(f"macro avg{'':<4} {np.mean([precision_score(y_test_binary, test_pred, pos_label=0, zero_division=0), precision]):.2f}      {np.mean([recall_score(y_test_binary, test_pred, pos_label=0, zero_division=0), recall]):.2f}     {np.mean([f1_score(y_test_binary, test_pred, pos_label=0, zero_division=0), f1]):.2f}       {len(y_test_binary)}")
        print(f"weighted avg{''} {precision_score(y_test_binary, test_pred, average='weighted', zero_division=0):.2f}      {recall_score(y_test_binary, test_pred, average='weighted', zero_division=0):.2f}     {f1_score(y_test_binary, test_pred, average='weighted', zero_division=0):.2f}       {len(y_test_binary)}")
        
        # Sujaukimo matrica
        cm = confusion_matrix(y_test_binary, test_pred)
        print("\nSujaukimo matrica:")
        print(f"TN: {cm[0,0]}, FP: {cm[0,1]}")
        print(f"FN: {cm[1,0]}, TP: {cm[1,1]}")

    # Po≈æymi≈≥ svarba
    importances = final_model.feature_importances_
    feature_names = X_final.columns
    feature_importance = pd.DataFrame({
        "Feature": feature_names,
        "Importance": importances
    }).sort_values(by="Importance", ascending=False)

    top_features = feature_importance.head(10)
    plt.figure(figsize=(10, 6))
    plt.barh(top_features["Feature"], top_features["Importance"], align="center")
    plt.gca().invert_yaxis()
    plt.xlabel("Svarba (feature importance)")
    plt.title("10 svarbiausi≈≥ po≈æymi≈≥ pagal ƒØtakƒÖ prognozei")
    plt.tight_layout()
    plt.show()

    # GridSearch rezultat≈≥ grafikas
    results = pd.DataFrame(grid_search.cv_results_)
    plt.figure(figsize=(10, 6))
    plt.plot(results['param_n_estimators'], -results['mean_test_score'], marker='o')
    plt.xlabel("n_estimators")
    plt.ylabel("Vidutinis MSE (CV)")
    plt.title("MSE priklausomybƒó nuo n_estimators")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    
    # Testavimo rezultat≈≥ grafikas
    if test_etapai:
        plt.figure(figsize=(12, 10))
        
        plt.subplot(2, 2, 1)
        plt.plot(test_etapai, test_accuracy, 'o-', label='Accuracy')
        plt.xlabel("Data")
        plt.ylabel("Accuracy")
        plt.title("Tikslumas pagal etapƒÖ")
        plt.grid(True)
        
        plt.subplot(2, 2, 2)
        plt.plot(test_etapai, test_precision, 'o-', label='Precision (klasƒó 1)')
        plt.xlabel("Data")
        plt.ylabel("Precision")
        plt.title("Precision pagal etapƒÖ")
        plt.grid(True)
        
        plt.subplot(2, 2, 3)
        plt.plot(test_etapai, test_recall, 'o-', label='Recall (klasƒó 1)')
        plt.xlabel("Data")
        plt.ylabel("Recall")
        plt.title("Recall pagal etapƒÖ")
        plt.grid(True)
        
        plt.subplot(2, 2, 4)
        plt.plot(test_etapai, test_f1, 'o-', label='F1-score (klasƒó 1)')
        plt.xlabel("Data")
        plt.ylabel("F1-score")
        plt.title("F1-score pagal etapƒÖ")
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # Sujaukimo matricos vizualizacija paskutiniam testavimo etapui
        if test_columns:
            y_last = df[test_columns[-1]].fillna(0).astype(int)
            raw_preds_last = final_model.predict(X_final)
            preds_last = adjust_predictions_by_format(raw_preds_last, test_columns[-1])
            
            plt.figure(figsize=(8, 6))
            cm_last = confusion_matrix(y_last, preds_last)
            sns.heatmap(cm_last, annot=True, fmt='d', cmap='Blues', 
                        xticklabels=['Nedalyvauja', 'Dalyvauja'],
                        yticklabels=['Nedalyvauja', 'Dalyvauja'])
            plt.xlabel('Prognozuota klasƒó')
            plt.ylabel('Tikroji klasƒó')
            plt.title(f'Sujaukimo matrica ({test_columns[-1]})')
            plt.tight_layout()
            plt.show()

    # I≈°saugome modelƒØ
    os.makedirs(output_dir, exist_ok=True)
    model_path = os.path.join(output_dir, f"model_{target_column.replace(' ', '_').replace('(', '').replace(')', '')}.pkl")
    joblib.dump((final_model, list(X_final.columns)), model_path)
    print(f"\nModelis i≈°saugotas: {model_path}")

    # Prognozavimas b≈´simam etapui
    if target_column not in competition_columns:
        print(f"\nüîÆ Prognozuojamas dalyvavimas b≈´simame etape: {target_column}")
        future_pred_raw = final_model.predict(X_final)
        future_pred = adjust_predictions_by_format(future_pred_raw, target_column)

        # Sukuriame DataFrame su prognozƒómis ir sportininki≈≥ tikimybi≈≥ reitingais
        predictions_df = pd.DataFrame({
            "IBUId": df["IBUId"],
            "FullName": df["FullName"],
            "RawScore": future_pred_raw,
            "PredictedParticipation": future_pred
        }).sort_values(by="RawScore", ascending=False)

        # I≈°saugome prognozes
        predictions_path = os.path.join(output_dir, f"predictions_{target_column.replace(' ', '_').replace('(', '').replace(')', '')}.csv")
        predictions_df.to_csv(predictions_path, index=False)
        print(f"Prognozƒós i≈°saugotos: {predictions_path}")
        print(f"Prognozuojamas dalyvi≈≥ skaiƒçius: {sum(future_pred)}")
        
        # Rodome TOP-10 sportininki≈≥ prognozes
        print("\nTOP-10 sportininki≈≥ pagal prognozuojamƒÖ dalyvavimo reitingƒÖ:")
        top_10 = predictions_df.head(10)
        for _, row in top_10.iterrows():
            print(f"{row['FullName']} (Reitingas: {row['RawScore']:.4f})")

def adjust_predictions_by_format(pred_scores, competition_name):
    if "Mass Start" in competition_name:
        target_count = 30
        format_type = "Mass Start"
    elif "Pursuit" in competition_name:
        target_count = 60
        format_type = "Pursuit"
    else:
        target_count = 100
        format_type = "Individual/Sprint"

    top_indices = np.argsort(pred_scores)[-target_count:]
    binary_selection = np.zeros_like(pred_scores, dtype=int)
    binary_selection[top_indices] = 1

    print(f"Pritaikytas formatas: {format_type} ({target_count} sportininkƒós)")
    return binary_selection

if __name__ == "__main__":
    predict_participation(
        data_path="data/female_athletes_binary_competitions.csv",
        target_column="2025-12-02 01 (15  Individual Competition) W"
    )